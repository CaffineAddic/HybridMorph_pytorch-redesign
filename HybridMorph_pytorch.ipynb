{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nExample script to train a VoxelMorph model.\\nYou will likely have to customize this script slightly to accommodate your own data. All images\\nshould be appropriately cropped and scaled to values between 0 and 1.\\nIf an atlas file is provided with the --atlas flag, then scan-to-atlas training is performed.\\nOtherwise, registration will be scan-to-scan.\\nIf you use this code, please cite the following, and read function docs for further info/citations.\\n    VoxelMorph: A Learning Framework for Deformable Medical Image Registration G. Balakrishnan, A.\\n    Zhao, M. R. Sabuncu, J. Guttag, A.V. Dalca. IEEE TMI: Transactions on Medical Imaging. 38(8). pp\\n    1788-1800. 2019. \\n    or\\n    Unsupervised Learning for Probabilistic Diffeomorphic Registration for Images and Surfaces\\n    A.V. Dalca, G. Balakrishnan, J. Guttag, M.R. Sabuncu. \\n    MedIA: Medical Image Analysis. (57). pp 226-236, 2019 \\nCopyright 2020 Adrian V. Dalca\\nLicensed under the Apache License, Version 2.0 (the \"License\"); you may not use this file except in\\ncompliance with the License. You may obtain a copy of the License at\\nhttp://www.apache.org/licenses/LICENSE-2.0\\nUnless required by applicable law or agreed to in writing, software distributed under the License is\\ndistributed on an \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or\\nimplied. See the License for the specific language governing permissions and limitations under the\\nLicense.\\n'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#!/usr/bin/env python\n",
    "\n",
    "\"\"\"\n",
    "Example script to train a VoxelMorph model.\n",
    "You will likely have to customize this script slightly to accommodate your own data. All images\n",
    "should be appropriately cropped and scaled to values between 0 and 1.\n",
    "If an atlas file is provided with the --atlas flag, then scan-to-atlas training is performed.\n",
    "Otherwise, registration will be scan-to-scan.\n",
    "If you use this code, please cite the following, and read function docs for further info/citations.\n",
    "    VoxelMorph: A Learning Framework for Deformable Medical Image Registration G. Balakrishnan, A.\n",
    "    Zhao, M. R. Sabuncu, J. Guttag, A.V. Dalca. IEEE TMI: Transactions on Medical Imaging. 38(8). pp\n",
    "    1788-1800. 2019. \n",
    "    or\n",
    "    Unsupervised Learning for Probabilistic Diffeomorphic Registration for Images and Surfaces\n",
    "    A.V. Dalca, G. Balakrishnan, J. Guttag, M.R. Sabuncu. \n",
    "    MedIA: Medical Image Analysis. (57). pp 226-236, 2019 \n",
    "Copyright 2020 Adrian V. Dalca\n",
    "Licensed under the Apache License, Version 2.0 (the \"License\"); you may not use this file except in\n",
    "compliance with the License. You may obtain a copy of the License at\n",
    "http://www.apache.org/licenses/LICENSE-2.0\n",
    "Unless required by applicable law or agreed to in writing, software distributed under the License is\n",
    "distributed on an \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or\n",
    "implied. See the License for the specific language governing permissions and limitations under the\n",
    "License.\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import random\n",
    "import argparse\n",
    "import time\n",
    "import numpy as np\n",
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import voxelmorph with pytorch backend\n",
    "os.environ['NEURITE_BACKEND'] = 'pytorch'\n",
    "os.environ['VXM_BACKEND'] = 'pytorch'\n",
    "import voxelmorph as vxm  # nopep8\n",
    "\n",
    "# parse the commandline\n",
    "parser = argparse.ArgumentParser()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "_StoreTrueAction(option_strings=['--multichannel'], dest='multichannel', nargs=0, const=True, default=False, type=None, choices=None, required=False, help='specify that data has multiple channels', metavar=None)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# data organization parameters\n",
    "parser.add_argument('--img-list', required=True, help='line-seperated list of training files')\n",
    "parser.add_argument('--img-prefix', help='optional input image file prefix')\n",
    "parser.add_argument('--img-suffix', help='optional input image file suffix')\n",
    "parser.add_argument('--atlas', help='atlas filename (default: data/atlas_norm.npz)')\n",
    "parser.add_argument('--model-dir', default='models',\n",
    "                    help='model output directory (default: models)')\n",
    "parser.add_argument('--multichannel', action='store_true',\n",
    "                    help='specify that data has multiple channels')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "_StoreTrueAction(option_strings=['--cudnn-nondet'], dest='cudnn_nondet', nargs=0, const=True, default=False, type=None, choices=None, required=False, help='disable cudnn determinism - might slow down training', metavar=None)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# training parameters\n",
    "parser.add_argument('--gpu', default='0', help='GPU ID number(s), comma-separated (default: 0)')\n",
    "parser.add_argument('--batch-size', type=int, default=1, help='batch size (default: 1)')\n",
    "parser.add_argument('--epochs', type=int, default=1500,\n",
    "                    help='number of training epochs (default: 1500)')\n",
    "parser.add_argument('--steps-per-epoch', type=int, default=100,\n",
    "                    help='frequency of model saves (default: 100)')\n",
    "parser.add_argument('--load-model', help='optional model file to initialize with')\n",
    "parser.add_argument('--initial-epoch', type=int, default=0,\n",
    "                    help='initial epoch number (default: 0)')\n",
    "parser.add_argument('--lr', type=float, default=1e-4, help='learning rate (default: 1e-4)')\n",
    "parser.add_argument('--cudnn-nondet', action='store_true',\n",
    "                    help='disable cudnn determinism - might slow down training')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "_StoreTrueAction(option_strings=['--bidir'], dest='bidir', nargs=0, const=True, default=False, type=None, choices=None, required=False, help='enable bidirectional cost function', metavar=None)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# network architecture parameters\n",
    "parser.add_argument('--enc', type=int, nargs='+',\n",
    "                    help='list of unet encoder filters (default: 16 32 32 32)')\n",
    "parser.add_argument('--dec', type=int, nargs='+',\n",
    "                    help='list of unet decorder filters (default: 32 32 32 32 32 16 16)')\n",
    "parser.add_argument('--int-steps', type=int, default=7,\n",
    "                    help='number of integration steps (default: 7)')\n",
    "parser.add_argument('--int-downsize', type=int, default=2,\n",
    "                    help='flow downsample factor for integration (default: 2)')\n",
    "parser.add_argument('--bidir', action='store_true', help='enable bidirectional cost function')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "ename": "ArgumentError",
     "evalue": "argument --image-loss: conflicting option string: --image-loss",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mArgumentError\u001b[0m                             Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[13], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[39m# loss hyperparameters\u001b[39;00m\n\u001b[0;32m----> 2\u001b[0m parser\u001b[39m.\u001b[39;49madd_argument(\u001b[39m'\u001b[39;49m\u001b[39m--image-loss\u001b[39;49m\u001b[39m'\u001b[39;49m, default\u001b[39m=\u001b[39;49m\u001b[39m'\u001b[39;49m\u001b[39mmse\u001b[39;49m\u001b[39m'\u001b[39;49m,\n\u001b[1;32m      3\u001b[0m                     help\u001b[39m=\u001b[39;49m\u001b[39m'\u001b[39;49m\u001b[39mimage reconstruction loss - can be mse or ncc (default: mse)\u001b[39;49m\u001b[39m'\u001b[39;49m)\n\u001b[1;32m      4\u001b[0m parser\u001b[39m.\u001b[39madd_argument(\u001b[39m'\u001b[39m\u001b[39m--lambda\u001b[39m\u001b[39m'\u001b[39m, \u001b[39mtype\u001b[39m\u001b[39m=\u001b[39m\u001b[39mfloat\u001b[39m, dest\u001b[39m=\u001b[39m\u001b[39m'\u001b[39m\u001b[39mweight\u001b[39m\u001b[39m'\u001b[39m, default\u001b[39m=\u001b[39m\u001b[39m0.01\u001b[39m,\n\u001b[1;32m      5\u001b[0m                     help\u001b[39m=\u001b[39m\u001b[39m'\u001b[39m\u001b[39mweight of deformation loss (default: 0.01)\u001b[39m\u001b[39m'\u001b[39m)\n\u001b[1;32m      6\u001b[0m args \u001b[39m=\u001b[39m parser\u001b[39m.\u001b[39mparse_args()\n",
      "File \u001b[0;32m~/miniconda3/envs/torch/lib/python3.9/argparse.py:1441\u001b[0m, in \u001b[0;36m_ActionsContainer.add_argument\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1438\u001b[0m     \u001b[39mexcept\u001b[39;00m \u001b[39mTypeError\u001b[39;00m:\n\u001b[1;32m   1439\u001b[0m         \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\u001b[39m\"\u001b[39m\u001b[39mlength of metavar tuple does not match nargs\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[0;32m-> 1441\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_add_action(action)\n",
      "File \u001b[0;32m~/miniconda3/envs/torch/lib/python3.9/argparse.py:1806\u001b[0m, in \u001b[0;36mArgumentParser._add_action\u001b[0;34m(self, action)\u001b[0m\n\u001b[1;32m   1804\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m_add_action\u001b[39m(\u001b[39mself\u001b[39m, action):\n\u001b[1;32m   1805\u001b[0m     \u001b[39mif\u001b[39;00m action\u001b[39m.\u001b[39moption_strings:\n\u001b[0;32m-> 1806\u001b[0m         \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_optionals\u001b[39m.\u001b[39;49m_add_action(action)\n\u001b[1;32m   1807\u001b[0m     \u001b[39melse\u001b[39;00m:\n\u001b[1;32m   1808\u001b[0m         \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_positionals\u001b[39m.\u001b[39m_add_action(action)\n",
      "File \u001b[0;32m~/miniconda3/envs/torch/lib/python3.9/argparse.py:1643\u001b[0m, in \u001b[0;36m_ArgumentGroup._add_action\u001b[0;34m(self, action)\u001b[0m\n\u001b[1;32m   1642\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m_add_action\u001b[39m(\u001b[39mself\u001b[39m, action):\n\u001b[0;32m-> 1643\u001b[0m     action \u001b[39m=\u001b[39m \u001b[39msuper\u001b[39;49m(_ArgumentGroup, \u001b[39mself\u001b[39;49m)\u001b[39m.\u001b[39;49m_add_action(action)\n\u001b[1;32m   1644\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_group_actions\u001b[39m.\u001b[39mappend(action)\n\u001b[1;32m   1645\u001b[0m     \u001b[39mreturn\u001b[39;00m action\n",
      "File \u001b[0;32m~/miniconda3/envs/torch/lib/python3.9/argparse.py:1455\u001b[0m, in \u001b[0;36m_ActionsContainer._add_action\u001b[0;34m(self, action)\u001b[0m\n\u001b[1;32m   1453\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m_add_action\u001b[39m(\u001b[39mself\u001b[39m, action):\n\u001b[1;32m   1454\u001b[0m     \u001b[39m# resolve any conflicts\u001b[39;00m\n\u001b[0;32m-> 1455\u001b[0m     \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_check_conflict(action)\n\u001b[1;32m   1457\u001b[0m     \u001b[39m# add to actions list\u001b[39;00m\n\u001b[1;32m   1458\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_actions\u001b[39m.\u001b[39mappend(action)\n",
      "File \u001b[0;32m~/miniconda3/envs/torch/lib/python3.9/argparse.py:1592\u001b[0m, in \u001b[0;36m_ActionsContainer._check_conflict\u001b[0;34m(self, action)\u001b[0m\n\u001b[1;32m   1590\u001b[0m \u001b[39mif\u001b[39;00m confl_optionals:\n\u001b[1;32m   1591\u001b[0m     conflict_handler \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_get_handler()\n\u001b[0;32m-> 1592\u001b[0m     conflict_handler(action, confl_optionals)\n",
      "File \u001b[0;32m~/miniconda3/envs/torch/lib/python3.9/argparse.py:1601\u001b[0m, in \u001b[0;36m_ActionsContainer._handle_conflict_error\u001b[0;34m(self, action, conflicting_actions)\u001b[0m\n\u001b[1;32m   1595\u001b[0m message \u001b[39m=\u001b[39m ngettext(\u001b[39m'\u001b[39m\u001b[39mconflicting option string: \u001b[39m\u001b[39m%s\u001b[39;00m\u001b[39m'\u001b[39m,\n\u001b[1;32m   1596\u001b[0m                    \u001b[39m'\u001b[39m\u001b[39mconflicting option strings: \u001b[39m\u001b[39m%s\u001b[39;00m\u001b[39m'\u001b[39m,\n\u001b[1;32m   1597\u001b[0m                    \u001b[39mlen\u001b[39m(conflicting_actions))\n\u001b[1;32m   1598\u001b[0m conflict_string \u001b[39m=\u001b[39m \u001b[39m'\u001b[39m\u001b[39m, \u001b[39m\u001b[39m'\u001b[39m\u001b[39m.\u001b[39mjoin([option_string\n\u001b[1;32m   1599\u001b[0m                              \u001b[39mfor\u001b[39;00m option_string, action\n\u001b[1;32m   1600\u001b[0m                              \u001b[39min\u001b[39;00m conflicting_actions])\n\u001b[0;32m-> 1601\u001b[0m \u001b[39mraise\u001b[39;00m ArgumentError(action, message \u001b[39m%\u001b[39m conflict_string)\n",
      "\u001b[0;31mArgumentError\u001b[0m: argument --image-loss: conflicting option string: --image-loss"
     ]
    }
   ],
   "source": [
    "# loss hyperparameters\n",
    "parser.add_argument('--image-loss', default='mse',\n",
    "                    help='image reconstruction loss - can be mse or ncc (default: mse)')\n",
    "parser.add_argument('--lambda', type=float, dest='weight', default=0.01,\n",
    "                    help='weight of deformation loss (default: 0.01)')\n",
    "args = parser.parse_args()\n",
    "\n",
    "bidir = args.bidir"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'args' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[12], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[39m# load and prepare training data\u001b[39;00m\n\u001b[0;32m----> 2\u001b[0m train_files \u001b[39m=\u001b[39m vxm\u001b[39m.\u001b[39mpy\u001b[39m.\u001b[39mutils\u001b[39m.\u001b[39mread_file_list(args\u001b[39m.\u001b[39mimg_list, prefix\u001b[39m=\u001b[39margs\u001b[39m.\u001b[39mimg_prefix,\n\u001b[1;32m      3\u001b[0m                                           suffix\u001b[39m=\u001b[39margs\u001b[39m.\u001b[39mimg_suffix)\n\u001b[1;32m      4\u001b[0m \u001b[39massert\u001b[39;00m \u001b[39mlen\u001b[39m(train_files) \u001b[39m>\u001b[39m \u001b[39m0\u001b[39m, \u001b[39m'\u001b[39m\u001b[39mCould not find any training data.\u001b[39m\u001b[39m'\u001b[39m\n\u001b[1;32m      6\u001b[0m \u001b[39m# no need to append an extra feature axis if data is multichannel\u001b[39;00m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'args' is not defined"
     ]
    }
   ],
   "source": [
    "# load and prepare training data\n",
    "train_files = vxm.py.utils.read_file_list(args.img_list, prefix=args.img_prefix,\n",
    "                                          suffix=args.img_suffix)\n",
    "assert len(train_files) > 0, 'Could not find any training data.'\n",
    "\n",
    "# no need to append an extra feature axis if data is multichannel\n",
    "add_feat_axis = not args.multichannel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if args.atlas:\n",
    "    # scan-to-atlas generator\n",
    "    atlas = vxm.py.utils.load_volfile(args.atlas, np_var='vol',\n",
    "                                      add_batch_axis=True, add_feat_axis=add_feat_axis)\n",
    "    generator = vxm.generators.scan_to_atlas(train_files, atlas,\n",
    "                                             batch_size=args.batch_size, bidir=args.bidir,\n",
    "                                             add_feat_axis=add_feat_axis)\n",
    "else:\n",
    "    # scan-to-scan generator\n",
    "    generator = vxm.generators.scan_to_scan(\n",
    "        train_files, batch_size=args.batch_size, bidir=args.bidir, add_feat_axis=add_feat_axis)\n",
    "\n",
    "# extract shape from sampled input\n",
    "inshape = next(generator)[0][0].shape[1:-1]\n",
    "\n",
    "# prepare model folder\n",
    "model_dir = args.model_dir\n",
    "os.makedirs(model_dir, exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# device handling\n",
    "gpus = args.gpu.split(',')\n",
    "nb_gpus = len(gpus)\n",
    "device = 'cuda'\n",
    "\n",
    "os.environ['CUDA_VISIBLE_DEVICES'] = args.gpu\n",
    "assert np.mod(args.batch_size, nb_gpus) == 0, \\\n",
    "    'Batch size (%d) should be a multiple of the nr of gpus (%d)' % (args.batch_size, nb_gpus)\n",
    "\n",
    "# enabling cudnn determinism appears to speed up training by a lot\n",
    "torch.backends.cudnn.deterministic = not args.cudnn_nondet\n",
    "\n",
    "# unet architecture\n",
    "enc_nf = args.enc if args.enc else [16, 32, 32, 32]\n",
    "dec_nf = args.dec if args.dec else [32, 32, 32, 32, 32, 16, 16]\n",
    "\n",
    "if args.load_model:\n",
    "    # load initial model (if specified)\n",
    "    model = vxm.networks.VxmDense.load(args.load_model, device)\n",
    "else:\n",
    "    # otherwise configure new model\n",
    "    model = vxm.networks.VxmDense(\n",
    "        inshape=inshape,\n",
    "        nb_unet_features=[enc_nf, dec_nf],\n",
    "        bidir=bidir,\n",
    "        int_steps=args.int_steps,\n",
    "        int_downsize=args.int_downsize\n",
    "    )\n",
    "\n",
    "if nb_gpus > 1:\n",
    "    # use multiple GPUs via DataParallel\n",
    "    model = torch.nn.DataParallel(model)\n",
    "    model.save = model.module.save\n",
    "\n",
    "# prepare the model for training and send to device\n",
    "model.to(device)\n",
    "model.train()\n",
    "\n",
    "# set optimizer\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=args.lr)\n",
    "\n",
    "# prepare image loss\n",
    "if args.image_loss == 'ncc':\n",
    "    image_loss_func = vxm.losses.NCC().loss\n",
    "elif args.image_loss == 'mse':\n",
    "    image_loss_func = vxm.losses.MSE().loss\n",
    "else:\n",
    "    raise ValueError('Image loss should be \"mse\" or \"ncc\", but found \"%s\"' % args.image_loss)\n",
    "\n",
    "# need two image loss functions if bidirectional\n",
    "if bidir:\n",
    "    losses = [image_loss_func, image_loss_func]\n",
    "    weights = [0.5, 0.5]\n",
    "else:\n",
    "    losses = [image_loss_func]\n",
    "    weights = [1]\n",
    "\n",
    "# prepare deformation loss\n",
    "losses += [vxm.losses.Grad('l2', loss_mult=args.int_downsize).loss]\n",
    "weights += [args.weight]\n",
    "\n",
    "# training loops\n",
    "for epoch in range(args.initial_epoch, args.epochs):\n",
    "\n",
    "    # save model checkpoint\n",
    "    if epoch % 20 == 0:\n",
    "        model.save(os.path.join(model_dir, '%04d.pt' % epoch))\n",
    "\n",
    "    epoch_loss = []\n",
    "    epoch_total_loss = []\n",
    "    epoch_step_time = []\n",
    "\n",
    "    for step in range(args.steps_per_epoch):\n",
    "\n",
    "        step_start_time = time.time()\n",
    "\n",
    "        # generate inputs (and true outputs) and convert them to tensors\n",
    "        inputs, y_true = next(generator)\n",
    "        inputs = [torch.from_numpy(d).to(device).float().permute(0, 4, 1, 2, 3) for d in inputs]\n",
    "        y_true = [torch.from_numpy(d).to(device).float().permute(0, 4, 1, 2, 3) for d in y_true]\n",
    "\n",
    "        # run inputs through the model to produce a warped image and flow field\n",
    "        y_pred = model(*inputs)\n",
    "\n",
    "        # calculate total loss\n",
    "        loss = 0\n",
    "        loss_list = []\n",
    "        for n, loss_function in enumerate(losses):\n",
    "            curr_loss = loss_function(y_true[n], y_pred[n]) * weights[n]\n",
    "            loss_list.append(curr_loss.item())\n",
    "            loss += curr_loss\n",
    "\n",
    "        epoch_loss.append(loss_list)\n",
    "        epoch_total_loss.append(loss.item())\n",
    "\n",
    "        # backpropagate and optimize\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        # get compute time\n",
    "        epoch_step_time.append(time.time() - step_start_time)\n",
    "\n",
    "    # print epoch info\n",
    "    epoch_info = 'Epoch %d/%d' % (epoch + 1, args.epochs)\n",
    "    time_info = '%.4f sec/step' % np.mean(epoch_step_time)\n",
    "    losses_info = ', '.join(['%.4e' % f for f in np.mean(epoch_loss, axis=0)])\n",
    "    loss_info = 'loss: %.4e  (%s)' % (np.mean(epoch_total_loss), losses_info)\n",
    "    print(' - '.join((epoch_info, time_info, loss_info)), flush=True)\n",
    "\n",
    "# final model save\n",
    "model.save(os.path.join(model_dir, '%04d.pt' % args.epochs))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "torch",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
